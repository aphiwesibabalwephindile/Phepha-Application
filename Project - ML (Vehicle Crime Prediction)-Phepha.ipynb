{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af15f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5152895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Place  Latitude  Longitude  Crime_ID Province  \\\n",
      "0   Altron Systems Integration  -26.0501    28.0569         1  Gauteng   \n",
      "1   Altron Systems Integration  -26.0501    28.0569         2  Gauteng   \n",
      "2   Altron Systems Integration  -26.0501    28.0569         3  Gauteng   \n",
      "3   Altron Systems Integration  -26.0501    28.0569         4  Gauteng   \n",
      "4   Altron Systems Integration  -26.0501    28.0569         5  Gauteng   \n",
      "..                         ...       ...        ...       ...      ...   \n",
      "95          Olivedale Randburg  -26.0557    27.9892        96  Gauteng   \n",
      "96          Nicolway Bryanston  -26.0521    28.0241        97  Gauteng   \n",
      "97          Nicolway Bryanston  -26.0521    28.0241        98  Gauteng   \n",
      "98          Nicolway Bryanston  -26.0521    28.0241        99  Gauteng   \n",
      "99          Nicolway Bryanston  -26.0521    28.0241       100  Gauteng   \n",
      "\n",
      "   Physical_Address      Car_Type  Year                Crime_Type  \\\n",
      "0   123 Main Street  Toyota Hilux  2021                 Hijacking   \n",
      "1   123 Main Street   Ford Ranger  2021            Remote Jamming   \n",
      "2   123 Main Street       VW Polo  2021            Smash and Grab   \n",
      "3   123 Main Street  Toyota Hilux  2022         Vehicle Vandalism   \n",
      "4   123 Main Street   Ford Ranger  2022  Organized Truck Lootings   \n",
      "..              ...           ...   ...                       ...   \n",
      "95   456 Elm Avenue   Ford Ranger  2023            Smash and Grab   \n",
      "96   789 Oak Street  Toyota Hilux  2021         Vehicle Vandalism   \n",
      "97   789 Oak Street   Ford Ranger  2021  Organized Truck Lootings   \n",
      "98   789 Oak Street       VW Polo  2021                 Hijacking   \n",
      "99   789 Oak Street  Toyota Hilux  2022            Remote Jamming   \n",
      "\n",
      "              Timestamp Time_Of_Day  \n",
      "0   2021-05-10T08:30:00     Morning  \n",
      "1   2021-06-20T14:45:00   Afternoon  \n",
      "2   2021-07-15T18:20:00     Evening  \n",
      "3   2022-02-05T10:10:00     Morning  \n",
      "4   2022-03-15T13:55:00   Afternoon  \n",
      "..                  ...         ...  \n",
      "95  2023-03-25T15:40:00   Afternoon  \n",
      "96  2021-08-18T11:20:00     Morning  \n",
      "97  2021-09-30T16:50:00   Afternoon  \n",
      "98  2021-11-05T19:15:00     Evening  \n",
      "99  2022-07-08T08:55:00     Morning  \n",
      "\n",
      "[100 rows x 11 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Crime_ID</th>\n",
       "      <th>Province</th>\n",
       "      <th>Physical_Address</th>\n",
       "      <th>Car_Type</th>\n",
       "      <th>Year</th>\n",
       "      <th>Crime_Type</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Time_Of_Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Altron Systems Integration</td>\n",
       "      <td>-26.0501</td>\n",
       "      <td>28.0569</td>\n",
       "      <td>1</td>\n",
       "      <td>Gauteng</td>\n",
       "      <td>123 Main Street</td>\n",
       "      <td>Toyota Hilux</td>\n",
       "      <td>2021</td>\n",
       "      <td>Hijacking</td>\n",
       "      <td>2021-05-10T08:30:00</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Altron Systems Integration</td>\n",
       "      <td>-26.0501</td>\n",
       "      <td>28.0569</td>\n",
       "      <td>2</td>\n",
       "      <td>Gauteng</td>\n",
       "      <td>123 Main Street</td>\n",
       "      <td>Ford Ranger</td>\n",
       "      <td>2021</td>\n",
       "      <td>Remote Jamming</td>\n",
       "      <td>2021-06-20T14:45:00</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Altron Systems Integration</td>\n",
       "      <td>-26.0501</td>\n",
       "      <td>28.0569</td>\n",
       "      <td>3</td>\n",
       "      <td>Gauteng</td>\n",
       "      <td>123 Main Street</td>\n",
       "      <td>VW Polo</td>\n",
       "      <td>2021</td>\n",
       "      <td>Smash and Grab</td>\n",
       "      <td>2021-07-15T18:20:00</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Altron Systems Integration</td>\n",
       "      <td>-26.0501</td>\n",
       "      <td>28.0569</td>\n",
       "      <td>4</td>\n",
       "      <td>Gauteng</td>\n",
       "      <td>123 Main Street</td>\n",
       "      <td>Toyota Hilux</td>\n",
       "      <td>2022</td>\n",
       "      <td>Vehicle Vandalism</td>\n",
       "      <td>2022-02-05T10:10:00</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Altron Systems Integration</td>\n",
       "      <td>-26.0501</td>\n",
       "      <td>28.0569</td>\n",
       "      <td>5</td>\n",
       "      <td>Gauteng</td>\n",
       "      <td>123 Main Street</td>\n",
       "      <td>Ford Ranger</td>\n",
       "      <td>2022</td>\n",
       "      <td>Organized Truck Lootings</td>\n",
       "      <td>2022-03-15T13:55:00</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Place  Latitude  Longitude  Crime_ID Province  \\\n",
       "0  Altron Systems Integration  -26.0501    28.0569         1  Gauteng   \n",
       "1  Altron Systems Integration  -26.0501    28.0569         2  Gauteng   \n",
       "2  Altron Systems Integration  -26.0501    28.0569         3  Gauteng   \n",
       "3  Altron Systems Integration  -26.0501    28.0569         4  Gauteng   \n",
       "4  Altron Systems Integration  -26.0501    28.0569         5  Gauteng   \n",
       "\n",
       "  Physical_Address      Car_Type  Year                Crime_Type  \\\n",
       "0  123 Main Street  Toyota Hilux  2021                 Hijacking   \n",
       "1  123 Main Street   Ford Ranger  2021            Remote Jamming   \n",
       "2  123 Main Street       VW Polo  2021            Smash and Grab   \n",
       "3  123 Main Street  Toyota Hilux  2022         Vehicle Vandalism   \n",
       "4  123 Main Street   Ford Ranger  2022  Organized Truck Lootings   \n",
       "\n",
       "             Timestamp Time_Of_Day  \n",
       "0  2021-05-10T08:30:00     Morning  \n",
       "1  2021-06-20T14:45:00   Afternoon  \n",
       "2  2021-07-15T18:20:00     Evening  \n",
       "3  2022-02-05T10:10:00     Morning  \n",
       "4  2022-03-15T13:55:00   Afternoon  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the dataset\n",
    "from google.cloud import storage\n",
    "Vehicle_CrimeDf = pd.read_excel('gs://phepha-bucket_1/ml_models/dummy data draft.xlsx', \n",
    "                              header = None, skiprows=1, names = ['Place', 'Latitude', 'Longitude', 'Crime_ID', 'Province', 'Physical_Address',\n",
    "                                                     'Car_Type', 'Year', 'Crime_Type', 'Timestamp', 'Time_Of_Day'])\n",
    "print(Vehicle_CrimeDf)\n",
    "Vehicle_CrimeDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35815b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place                object\n",
      "Latitude            float64\n",
      "Longitude           float64\n",
      "Crime_ID              int64\n",
      "Province             object\n",
      "Physical_Address     object\n",
      "Car_Type             object\n",
      "Year                  int64\n",
      "Crime_Type           object\n",
      "Timestamp            object\n",
      "Time_Of_Day          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Checking data types of the dataset's variables\n",
    "print(Vehicle_CrimeDf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1e62bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No need to change the variable's data types since they are read correctly\n",
    "#No need to check for duplicated columns and handle them\n",
    "#No need to check for duplicated rows and handle them\n",
    "#No need to check for missing values and them them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "84541997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Place  Latitude  Longitude      Car_Type  Year  \\\n",
      "0   Altron Systems Integration  -26.0501    28.0569  Toyota Hilux  2021   \n",
      "1   Altron Systems Integration  -26.0501    28.0569   Ford Ranger  2021   \n",
      "2   Altron Systems Integration  -26.0501    28.0569       VW Polo  2021   \n",
      "3   Altron Systems Integration  -26.0501    28.0569  Toyota Hilux  2022   \n",
      "4   Altron Systems Integration  -26.0501    28.0569   Ford Ranger  2022   \n",
      "..                         ...       ...        ...           ...   ...   \n",
      "95          Olivedale Randburg  -26.0557    27.9892   Ford Ranger  2023   \n",
      "96          Nicolway Bryanston  -26.0521    28.0241  Toyota Hilux  2021   \n",
      "97          Nicolway Bryanston  -26.0521    28.0241   Ford Ranger  2021   \n",
      "98          Nicolway Bryanston  -26.0521    28.0241       VW Polo  2021   \n",
      "99          Nicolway Bryanston  -26.0521    28.0241  Toyota Hilux  2022   \n",
      "\n",
      "                  Crime_Type            Timestamp Time_Of_Day  \n",
      "0                  Hijacking  2021-05-10T08:30:00     Morning  \n",
      "1             Remote Jamming  2021-06-20T14:45:00   Afternoon  \n",
      "2             Smash and Grab  2021-07-15T18:20:00     Evening  \n",
      "3          Vehicle Vandalism  2022-02-05T10:10:00     Morning  \n",
      "4   Organized Truck Lootings  2022-03-15T13:55:00   Afternoon  \n",
      "..                       ...                  ...         ...  \n",
      "95            Smash and Grab  2023-03-25T15:40:00   Afternoon  \n",
      "96         Vehicle Vandalism  2021-08-18T11:20:00     Morning  \n",
      "97  Organized Truck Lootings  2021-09-30T16:50:00   Afternoon  \n",
      "98                 Hijacking  2021-11-05T19:15:00     Evening  \n",
      "99            Remote Jamming  2022-07-08T08:55:00     Morning  \n",
      "\n",
      "[100 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#Drop predictor variables that will not be effective at predicting the response variable\n",
    "Dropped_Predictor_Variables = ['Crime_ID', 'Province', 'Physical_Address']\n",
    "DropVehicle_CrimeDf = Vehicle_CrimeDf.drop(Dropped_Predictor_Variables, axis=1)\n",
    "print(DropVehicle_CrimeDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a48de92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Place  Latitude  Longitude  Car_Type  Year  Crime_Type  \\\n",
      "0       0  -26.0501    28.0569         1  2021           0   \n",
      "1       0  -26.0501    28.0569         0  2021           2   \n",
      "2       0  -26.0501    28.0569         2  2021           3   \n",
      "3       0  -26.0501    28.0569         1  2022           4   \n",
      "4       0  -26.0501    28.0569         0  2022           1   \n",
      "..    ...       ...        ...       ...   ...         ...   \n",
      "95      3  -26.0557    27.9892         0  2023           3   \n",
      "96      2  -26.0521    28.0241         1  2021           4   \n",
      "97      2  -26.0521    28.0241         0  2021           1   \n",
      "98      2  -26.0521    28.0241         2  2021           0   \n",
      "99      2  -26.0521    28.0241         1  2022           2   \n",
      "\n",
      "              Timestamp  Time_Of_Day  \n",
      "0   2021-05-10T08:30:00            2  \n",
      "1   2021-06-20T14:45:00            0  \n",
      "2   2021-07-15T18:20:00            1  \n",
      "3   2022-02-05T10:10:00            2  \n",
      "4   2022-03-15T13:55:00            0  \n",
      "..                  ...          ...  \n",
      "95  2023-03-25T15:40:00            0  \n",
      "96  2021-08-18T11:20:00            2  \n",
      "97  2021-09-30T16:50:00            0  \n",
      "98  2021-11-05T19:15:00            1  \n",
      "99  2022-07-08T08:55:00            2  \n",
      "\n",
      "[100 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#Encoding categorical variables using \"Label Encoding\"\n",
    "# Perform label encoding on categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for column in ['Car_Type','Time_Of_Day', 'Place', 'Crime_Type', 'Time_Of_Day']:\n",
    "    DropVehicle_CrimeDf[column] = label_encoder.fit_transform(DropVehicle_CrimeDf[column])\n",
    "\n",
    "print(DropVehicle_CrimeDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f3e4b3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Place  Latitude  Longitude  Car_Type  Year  Crime_Type  Time_Of_Day  \\\n",
      "0       0  -26.0501    28.0569         1  2021           0            2   \n",
      "1       0  -26.0501    28.0569         0  2021           2            0   \n",
      "2       0  -26.0501    28.0569         2  2021           3            1   \n",
      "3       0  -26.0501    28.0569         1  2022           4            2   \n",
      "4       0  -26.0501    28.0569         0  2022           1            0   \n",
      "..    ...       ...        ...       ...   ...         ...          ...   \n",
      "95      3  -26.0557    27.9892         0  2023           3            0   \n",
      "96      2  -26.0521    28.0241         1  2021           4            2   \n",
      "97      2  -26.0521    28.0241         0  2021           1            0   \n",
      "98      2  -26.0521    28.0241         2  2021           0            1   \n",
      "99      2  -26.0521    28.0241         1  2022           2            2   \n",
      "\n",
      "          Date  \n",
      "0   2021-05-10  \n",
      "1   2021-06-20  \n",
      "2   2021-07-15  \n",
      "3   2022-02-05  \n",
      "4   2022-03-15  \n",
      "..         ...  \n",
      "95  2023-03-25  \n",
      "96  2021-08-18  \n",
      "97  2021-09-30  \n",
      "98  2021-11-05  \n",
      "99  2022-07-08  \n",
      "\n",
      "[100 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamp column to datetime dtype\n",
    "DropVehicle_CrimeDf['Timestamp'] = pd.to_datetime(DropVehicle_CrimeDf['Timestamp'])\n",
    "\n",
    "# Extract date from timestamp\n",
    "DropVehicle_CrimeDf['Date'] = DropVehicle_CrimeDf['Timestamp'].dt.date\n",
    "\n",
    "# Drop the original timestamp column if it's no longer needed\n",
    "DropVehicle_CrimeDf.drop(columns=['Timestamp'], inplace=True)\n",
    "\n",
    "# Show the DataFrame with new columns\n",
    "print(DropVehicle_CrimeDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89024f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Place  Latitude  Longitude  Car_Type  Year  Crime_Type  Time_Of_Day  \\\n",
      "0       0  -26.0501    28.0569         1  2021           0            2   \n",
      "1       0  -26.0501    28.0569         0  2021           2            0   \n",
      "2       0  -26.0501    28.0569         2  2021           3            1   \n",
      "3       0  -26.0501    28.0569         1  2022           4            2   \n",
      "4       0  -26.0501    28.0569         0  2022           1            0   \n",
      "..    ...       ...        ...       ...   ...         ...          ...   \n",
      "95      3  -26.0557    27.9892         0  2023           3            0   \n",
      "96      2  -26.0521    28.0241         1  2021           4            2   \n",
      "97      2  -26.0521    28.0241         0  2021           1            0   \n",
      "98      2  -26.0521    28.0241         2  2021           0            1   \n",
      "99      2  -26.0521    28.0241         1  2022           2            2   \n",
      "\n",
      "          Date  Day  Month  \n",
      "0   2021-05-10   10      5  \n",
      "1   2021-06-20   20      6  \n",
      "2   2021-07-15   15      7  \n",
      "3   2022-02-05    5      2  \n",
      "4   2022-03-15   15      3  \n",
      "..         ...  ...    ...  \n",
      "95  2023-03-25   25      3  \n",
      "96  2021-08-18   18      8  \n",
      "97  2021-09-30   30      9  \n",
      "98  2021-11-05    5     11  \n",
      "99  2022-07-08    8      7  \n",
      "\n",
      "[100 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract day, month, and year\n",
    "DropVehicle_CrimeDf['Day'] = DropVehicle_CrimeDf['Date'].apply(lambda x: x.day)\n",
    "DropVehicle_CrimeDf['Month'] = DropVehicle_CrimeDf['Date'].apply(lambda x: x.month)\n",
    "DropVehicle_CrimeDf['Year'] = DropVehicle_CrimeDf['Date'].apply(lambda x: x.year)\n",
    "\n",
    "# Show the DataFrame with new columns\n",
    "print(DropVehicle_CrimeDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac9aa034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Place  Latitude  Longitude  Car_Type  Year  Crime_Type  Time_Of_Day  Day  \\\n",
      "0       0  -26.0501    28.0569         1  2021           0            2   10   \n",
      "1       0  -26.0501    28.0569         0  2021           2            0   20   \n",
      "2       0  -26.0501    28.0569         2  2021           3            1   15   \n",
      "3       0  -26.0501    28.0569         1  2022           4            2    5   \n",
      "4       0  -26.0501    28.0569         0  2022           1            0   15   \n",
      "..    ...       ...        ...       ...   ...         ...          ...  ...   \n",
      "95      3  -26.0557    27.9892         0  2023           3            0   25   \n",
      "96      2  -26.0521    28.0241         1  2021           4            2   18   \n",
      "97      2  -26.0521    28.0241         0  2021           1            0   30   \n",
      "98      2  -26.0521    28.0241         2  2021           0            1    5   \n",
      "99      2  -26.0521    28.0241         1  2022           2            2    8   \n",
      "\n",
      "    Month  \n",
      "0       5  \n",
      "1       6  \n",
      "2       7  \n",
      "3       2  \n",
      "4       3  \n",
      "..    ...  \n",
      "95      3  \n",
      "96      8  \n",
      "97      9  \n",
      "98     11  \n",
      "99      7  \n",
      "\n",
      "[100 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'Date' variable\n",
    "DropVehicle_CrimeDf.drop(columns=['Date'], inplace=True)\n",
    "\n",
    "# Show the DataFrame with new columns\n",
    "print(DropVehicle_CrimeDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "19bb34d8-7aea-4e39-b9f8-f987c6bdf432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (70, 6)\n",
      "X_test shape: (30, 6)\n",
      "y_train shape: (70, 2)\n",
      "y_test shape: (30, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Split the data into features and target variable\n",
    "X = DropVehicle_CrimeDf[['Place','Car_Type', 'Time_Of_Day', 'Day', 'Month', 'Year']]\n",
    "y = DropVehicle_CrimeDf[['Latitude', 'Longitude']]\n",
    "\n",
    "# Perform data normalization\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets and applying a stratified sampling method\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=2024, stratify = y)\n",
    "\n",
    "# Print the shapes of the training and test sets to verify the split\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3080a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original latitude class proportions:\n",
      "Latitude\n",
      "-26.0521    0.16\n",
      "-26.0501    0.15\n",
      "-26.0365    0.12\n",
      "-26.1076    0.12\n",
      "-26.0722    0.12\n",
      "-26.0557    0.09\n",
      "-26.0305    0.06\n",
      "-26.0698    0.06\n",
      "-26.0874    0.06\n",
      "-26.0412    0.06\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Training latitude class proportions:\n",
      "[0.12857143 0.05714286 0.12857143 0.05714286 0.08571429 0.15714286\n",
      " 0.15714286 0.05714286 0.11428571 0.05714286]\n",
      "\n",
      "Test latitude class proportions:\n",
      "[0.1        0.06666667 0.1        0.06666667 0.1        0.16666667\n",
      " 0.13333333 0.06666667 0.13333333 0.06666667]\n",
      "\n",
      "Original longitude class proportions:\n",
      "Longitude\n",
      "28.0241    0.16\n",
      "28.0569    0.15\n",
      "28.0561    0.12\n",
      "28.0567    0.12\n",
      "28.0720    0.12\n",
      "27.9892    0.09\n",
      "28.0337    0.06\n",
      "28.0551    0.06\n",
      "28.0606    0.06\n",
      "28.0724    0.06\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Training longitude class proportions:\n",
      "[0.08571429 0.15714286 0.05714286 0.05714286 0.11428571 0.12857143\n",
      " 0.15714286 0.05714286 0.12857143 0.05714286]\n",
      "\n",
      "Test longitude class proportions:\n",
      "[0.1        0.16666667 0.06666667 0.06666667 0.13333333 0.1\n",
      " 0.13333333 0.06666667 0.1        0.06666667]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the proportions of each class in the original dataset for latitude\n",
    "original_latitude_proportions = DropVehicle_CrimeDf['Latitude'].value_counts(normalize=True)\n",
    "\n",
    "# Calculate the proportions of each class in the training set for latitude\n",
    "train_latitude_proportions = np.unique(y_train['Latitude'], return_counts=True)[1] / len(y_train)\n",
    "\n",
    "# Calculate the proportions of each class in the test set for latitude\n",
    "test_latitude_proportions = np.unique(y_test['Latitude'], return_counts=True)[1] / len(y_test)\n",
    "\n",
    "# Calculate the proportions of each class in the original dataset for longitude\n",
    "original_longitude_proportions = DropVehicle_CrimeDf['Longitude'].value_counts(normalize=True)\n",
    "\n",
    "# Calculate the proportions of each class in the training set for longitude\n",
    "train_longitude_proportions = np.unique(y_train['Longitude'], return_counts=True)[1] / len(y_train)\n",
    "\n",
    "# Calculate the proportions of each class in the test set for longitude\n",
    "test_longitude_proportions = np.unique(y_test['Longitude'], return_counts=True)[1] / len(y_test)\n",
    "\n",
    "# Print the original, training, and test class proportions for latitude\n",
    "print(\"Original latitude class proportions:\")\n",
    "print(original_latitude_proportions)\n",
    "print(\"\\nTraining latitude class proportions:\")\n",
    "print(train_latitude_proportions)\n",
    "print(\"\\nTest latitude class proportions:\")\n",
    "print(test_latitude_proportions)\n",
    "\n",
    "# Print the original, training, and test class proportions for longitude\n",
    "print(\"\\nOriginal longitude class proportions:\")\n",
    "print(original_longitude_proportions)\n",
    "print(\"\\nTraining longitude class proportions:\")\n",
    "print(train_longitude_proportions)\n",
    "print(\"\\nTest longitude class proportions:\")\n",
    "print(test_longitude_proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60f81743-a790-4027-850c-74af81e43faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 21.1308\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 45.1343\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0321\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4703\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7799\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2715\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4663\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3632\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6307\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0865\n",
      "Mean Test Loss across 10 folds: 7.536569605767727\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(2024)\n",
    "np.random.seed(2024)\n",
    "\n",
    "# Define the architecture of your neural network\n",
    "ANN_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)  # Output layer with 2 neurons for latitude and longitude\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "ANN_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "\n",
    "# Initialize lists to store the evaluation loss for each fold\n",
    "losses = []\n",
    "\n",
    "# Initialize the KFold object\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=2024)\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "for train_index, test_index in kf.split(X_normalized):\n",
    "    # Split the data into training and test sets for this fold\n",
    "    X_train_fold, X_test_fold = X_normalized[train_index], X_normalized[test_index]\n",
    "    y_train_fold, y_test_fold = y.values[train_index], y.values[test_index]\n",
    "    \n",
    "    # Train the model on this fold\n",
    "    history = ANN_model.fit(X_train_fold, y_train_fold, epochs=50, validation_split=0.2, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Evaluate the model on the test set for this fold\n",
    "    loss =ANN_model.evaluate(X_test_fold, y_test_fold)\n",
    "    \n",
    "    # Append the loss to the list\n",
    "    losses.append(loss)\n",
    "\n",
    "# Calculate the mean loss across all folds\n",
    "mean_loss = np.mean(losses)\n",
    "\n",
    "print(\"Mean Test Loss across 10 folds:\", mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5c420d2-e644-495d-a510-7372aec879f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[-26.104132  28.10414 ]\n",
      " [-26.480549  28.385975]\n",
      " [-26.475426  28.5617  ]\n",
      " [-26.204103  28.33531 ]\n",
      " [-25.425133  27.320507]\n",
      " [-25.477156  27.269213]\n",
      " [-26.923815  28.986744]\n",
      " [-26.311134  28.148829]\n",
      " [-26.00533   27.91229 ]\n",
      " [-26.194912  28.16133 ]\n",
      " [-26.204103  28.33531 ]\n",
      " [-26.137518  28.013237]\n",
      " [-26.182884  28.285307]\n",
      " [-26.694641  28.660625]\n",
      " [-25.546305  27.524584]\n",
      " [-26.18564   28.161165]\n",
      " [-26.517668  28.80287 ]\n",
      " [-26.194433  28.2438  ]\n",
      " [-26.066858  28.084494]\n",
      " [-26.041086  28.158865]\n",
      " [-25.900366  27.70267 ]\n",
      " [-26.420994  28.259798]\n",
      " [-26.448267  28.480883]\n",
      " [-26.480549  28.385975]\n",
      " [-25.796738  27.721956]\n",
      " [-25.698305  27.611107]\n",
      " [-23.323946  24.97196 ]\n",
      " [-26.137518  28.013237]\n",
      " [-26.575708  28.40526 ]\n",
      " [-25.663383  27.572027]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = ANN_model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ccb6d27d-ad44-4d1e-8a96-44d5890097fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions have been saved to C:\\Users\\Aphiwe.Magaya\\Downloads\\predictions.xlsx\n"
     ]
    }
   ],
   "source": [
    "# If not, you may need to reshape it accordingly\n",
    "# Assuming y_pred has shape (n_samples, 2)\n",
    "# If not, adjust the column names accordingly\n",
    "predictions_df = pd.DataFrame({'Latitude': y_pred[:, 0], 'Longitude': y_pred[:, 1]})\n",
    "\n",
    "# Specify the file path where you want to save the Excel file\n",
    "file_path = 'C:\\\\Users\\\\Aphiwe.Magaya\\\\Downloads\\\\predictions.xlsx'\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "predictions_df.to_excel(file_path, index=False)\n",
    "\n",
    "print(\"Predictions have been saved to\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f4bdf86-2f4f-4155-baa4-0bc8b740b284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "Mean Absolute Percentage Error (MAPE): 0.014872489219236418\n",
      "Mean Absolute Error (MAE): 0.4024916073608399\n",
      "Root Mean Squared Error (RMSE): 0.6504628898684969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ANN_model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e307083c-33cb-47e1-a234-ab8f4d203c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "#ANN_model.save(\"C:\\\\Users\\\\Aphiwe.Magaya\\\\OneDrive - Altron Group\\\\Documents\\\\PhePhaApp\\\\phepha_app\\\\assets\\\\ANN_model.keras\")\n",
    "\n",
    "# Convert the model to TensorFlow Lite format\n",
    "#converter = tf.lite.TFLiteConverter.from_keras_model(ANN_model)\n",
    "#tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model to a file\n",
    "#with open('C:\\\\Users\\\\Aphiwe.Magaya\\\\OneDrive - Altron Group\\\\Documents\\\\PhePhaApp\\\\phepha_app\\\\assets\\\\ANN_model.tflite', 'wb') as f:\n",
    "#    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ec9f3afb-5c07-41cd-aff0-6641de0bae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gcsfs\n",
    "import pickle\n",
    "\n",
    "# Initialize a GCS file system\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "\n",
    "# Serialize the model\n",
    "model_bytes = pickle.dumps(ANN_model)\n",
    "\n",
    "# Write the model bytes to a file in GCS\n",
    "with fs.open('phepha-bucket_1/ml_models/model.pkl', 'wb') as f:\n",
    "    f.write(model_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c4451338-261d-4ce4-a2b4-b882d2a8ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "\n",
    "# Save the best model to the specified directory\n",
    "#ANN_model.save(\"C:\\\\Users\\\\Aphiwe.Magaya\\\\OneDrive - Altron Group\\\\Documents\\\\PhePhaApp\\\\phepha_app\\\\assets\\\\ANN_model.keras\")\n",
    "#joblib.dump(ANN_model, 'C:\\\\Users\\\\Aphiwe.Magaya\\\\OneDrive - Altron Group\\\\Documents\\\\PhePhaApp\\\\phepha_app\\\\assets\\\\ANN_model.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e270779-8ac3-4e89-a77d-d4c3cb27ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.cloud import firestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "811abe4e-83bc-433c-b4fa-105c20ae8aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Firestore collection to save data into\n",
    "#collection_name = 'coordinates'\n",
    "# Loop through each row in the DataFrame and write it to Firestore\n",
    "#for idx, row in predictions_df.iterrows():     \n",
    "    # Create a document reference    \n",
    "#    doc_ref = db.collection(collection_name).document(f'record_{idx}') \n",
    "#   geo_point = firestore.GeoPoint(row['Latitude'], row['Longitude'])\n",
    "#    # Write data to Firestore   \n",
    "#    doc_ref.set({           \n",
    "#    u'geopoint': geo_point,\n",
    "#    u'crimeLevel': \"mlCrime\",\n",
    "#    u'raduis':100  \n",
    "#    })\n",
    "#print(\"Data written to Firestore successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
